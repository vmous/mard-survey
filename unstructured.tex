\section{Unstructured \p\ Networks}
\label{section:unstructured}

In this section, we present algorithms that tackle the topology mismatch
problem in unstructured \p\ networks. We classify them based on their
use of the overlay structure, their message forwarding scheme 
for peer communication and the techniques they use for detecting
proximity, to be used to optimize their overlay topology.

\subsection{Algorithms for Unstructured Architectures}

% TODO: READ A Near-Optimal Algorithm Attacking the Topology Mismatch Problem in Unstructured Peer-to-Peer Networks)

% BROADCAST OPTIMIZATION

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Improving search in peer-to-peer networks}

% \begin{figure}[ht]
% \centering
% \subfigure[Iterative deepening with three levels.] {
%   \includegraphics[scale=0.4]{img/algorithms/iterative_deepening}
%   \label{figure:dbfs:iterdeep}
% }\qquad\qquad
% \subfigure[Directed BFS.] {
%   \includegraphics[scale=0.4]{img/algorithms/directed_bfs}
%   \label{figure:dbfs:dbfs}
% }\qquad\qquad
% \subfigure[Local indices with radius size equal to $2$.] {
%   \includegraphics[scale=0.4]{img/algorithms/local_indices}
%   \label{figure:dbfs:localindx}
% }
% \caption{Improving search in P2P networks}
% \label{figure:dbfs}
% \end{figure}

To improve over {\sl Gnutella}'s ``blind flooding'' approach,
\cite{YG-M2002} proposed a practical and easy to implement solution 
weaved around three different message forwarding methods:
\emph{iterative deepening},
\emph{directed BFS}, and \emph{local indices}.

In \emph{iterative deepening}, 
%(see Figure~\ref{figure:dbfs:iterdeep})
the search is
performed on a BFS tree with multiple preset depths. 
The depth limit is iteratively increased by the source node for each query, 
based on the quality of the results. 
The source node may issue a new request with increased depth limit
that will trigger the nodes at the last depth level to resume the search. 
The iterative approach avoids restarting the entire search process 
from scratch at each iteration and reduces the load on the nodes of 
the upper levels of the tree. 
Its major drawback is the delay between successive iterations, as the
source-node has to examine the results at each attempt before deciding to
either quit or ``unfreeze'' the query.

The \emph{directed BFS}
tries to avoid the aforementioned delay by forwarding 
query messages only to a selected subset of available neighbors. The selection
criteria varies, from the number of results received previously or the distance
in terms of hops traveled to locate these results, to the bandwidth, or the
query load of the neighbor. That way, fewer nodes are visited but quality of
query responses is maintained, to a large degree, on the premise that the
selected heuristics can direct the search to the right path.
%
In \emph{local indices},
each node indexes data within a radius of $r$ hops and uses 
this local index to answer queries % on behalf of them 
without generating additional traffic. Local indices
greatly reduce the aggregate bandwidth usage of the network and 
improve query efficiency. However, updating such indices in 
the presence of frequent node joins/departures 
may introduce significant overhead should the radius is kept broad.
%%
Below, we outline how the techniques in~\cite{YG-M2002}
fare against the $3$ major performance criteria 
of Section~\ref{section:background}.
% \begin{center}
% \begin{tabular}{ccc}
% \textbf{Efficiency} & \textbf{Overhead} & \textbf{Scalability} \\
% \hline
% Iterative Deepening & ? & ? & ?
% Directed BFS & ? & ? & ?
% Local Indices & ? & ? & ?
% \end{tabular}
% \end{center}
\begin{center}
{\footnotesize
\begin{tabular}{rccc}
\multicolumn{1}{r}{} &
\multicolumn{1}{c}{\emph{Efficiency}} &
\multicolumn{1}{c}{\emph{Overhead}} &
\multicolumn{1}{c}{\emph{Scalability}}
\\
\cline{2-4}
\emph{Iterative Deepening} &
% needs recalculation in every iteration step
% extra delay imposed in a high churn environment that prohibits the algorithm
% to start from the last level of nodes and results in a restart of the whole
% process
low &
% the process in not started from the beginning at each iteration step
low &
% 
medium \\
\emph{Directed BFS} &
% Better time to satisfaction compared to iterative deepening
medium &
% Better quality and quicker results mean more aggregate bandwidth and
% processing power needs to be consumed since more nodes are involved (death
% spiral).
medium &
% BFS is Gnutella's non efficient communication method
medium \\
\emph{Local Indices} &
% efficiency is enhanced greatly since data pointers are replicated across the
% network
high &
% updating indices is a time and resource consuming process.
medium &
% the scalability is constrained by the indices update in a highly dynamic
% environment (high churn)
medium \\
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \paragraph*{ \bf Delay Aware P2P System}
A \emph{delay--aware} \p\ system termed {\sl DAPS} 
was introduced in~\cite{ZL2005}.
{\sl DAPS}  seeks to attain reduced look-up times by dividing 
peer routing tables into several sectors of increasing delay. 
The source node that issues the query designates the delay 
boundary it may tolerate, providing so a \emph{pruning factor}.
In this context, user requests are forwarded only to 
nodes whose expected delay is less than or equal to the indicated boundary. 
{\sl DAPS} primarily focuses on user ``experience'' and deploys an
end-to-end delay monitoring mechanism that  may enable
the clustering of routing tables. 
In an dynamic environment, the formation 
of very accurate such routing tables might be however an elusive goal.
%With the clustered
%routing tables and the loose organization of DAPS' overlay network it is
%considered by is be tween structured and unstructured.
%%
In terms of the $3$ performance criteria, {\sl DAPS} stands as follows:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% Does not check for close by nodes, it just sorts the contents of a node's
% routing table.
% Also in a high churn environment a lot of time could be spend probing for
% distances, resorting routing tables and creating sectors. Moreover it just
% prunes distant neighbout
low &
% Sorting routing table entries is done locally so it is not affecting.
low &
%
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Gia}

The key objective of the {\sl Gia} system~\cite{CRBLS2003} is 
to help alleviate the scalability omnipresent
in unstructured \p\ file-sharing systems.
At first, {\sl Gia} replaced {\sl Gnutella}'s blind flooding 
with random walks.
Although this adoption was 
a step in the right direction~\cite{lv_randomwalks_2002},
issuing a single copy of the query within the network
effectively reduces the search scope and may negatively affect 
the success rate of the query in question.
To overcome this limitation, {\sl Gia} introduces
a token-based flow control mechanism 
that gradually redirects queries to nodes which are more
likely to answer. This flow control mechanism also helps prevent node
overloading as each peer ``announces'' the number of query requests it 
can handle, in terms of tokens, to its neighbors; to this end, 
peers only forward query requests to nodes that they previously
received tokens from. Further refinement to the search mechanism is the
support for \emph{one--hop replication} of pointers to content.
{\sl Gia} also acknowledges the heterogeneity in peer bandwidth,
processing power, disk speed, etc., of \p\ nodes and uses this
information when connecting nodes to each other.
By using a topology adaptation algorithm, 
{\sl Gia} places low capacity nodes within 
short proximity to peers with high performance features.
This topology adaptation algorithm is based on the metric 
each node maintains about its satisfaction --ranging between $0$ and $1$--
for the neighbors it finds itself associated with. 
Through message exchange, a peer can establish new connections 
or drop superseded ones in order to improve its satisfaction.
Despite the fact that {\sl Gia}'s topology adaptation algorithm 
that primarily focuses on the satisfaction of peers improves the network's 
scalability, it falls short in addressing the mismatch problem
as considerations for the underlying network are not handled in explicit
terms.
%
In terms of the $3$ stated criteria, {\sl Gia}'s approach is as follows:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% Reduces the search scope.
medium &
% Only one copy of the query is issued to the network.
% A token based flow control mechanism redirects queries to nodes that are most
% likely to fulfill them.
low &
% Even thought the low overhead scalability is reduced by the reducing of
% search scope.
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Distributed Cycle Minimization Protocol (DCMP)}
Another problem with topology unaware
systems is the duplication of messages due to cycles in the network graph.
Interestingly, such cycles appear even along the correct forwarding path.
\cite{ZKB2008}~focuses on this exact deficiency of overlay networks and
introduces the \emph{Distributed Cycle Minimization Protocol
(DCMP)}, a dynamic, fully distributed method that removes cycles;
this is accomplished without sacrificing
overlay connectivity, resilience and other key properties of unstructured
\p\ architectures and by avoiding a hierarchical organization of peers. 
Once a cycle is detected in {\it DCMP}, the most powerful node in that cycle 
is elected as the \emph{Gate Peer} and the cycle is then broken in that place
that it will result in the minimization of the distance between the
\emph{Gate Peer} and all other nodes that are currently part of the cycle. 
This process is managed by using two specialized message types 
namely, \emph{Information Collection Message (ICM)} and \emph{Cut Message (CM)}. 
\emph{DCMP} bases its operation on messages whose travel is limited by an
imposed $TTL$ value (max set to $7$ for most cases). This inherently limits
the protocol in detecting cycles that span for more than $TTL$ nodes.
Even though cycle elimination does improve network performance, 
it cannot  directly contribute in the solution of the topology mismatch problem.
%
%\begin{figure}
%\centering
%  \includegraphics[scale=0.4]{img/dcmp.jpeg}
%\caption{Cycle elimination methods in DCMP}
%\label{figure:dcmp}
%\end{figure}
%
% TODO: SOME DISCUSSION
%Actually, the duplicate packet problem seems to hurt more the active nodes;
%those with higher capacities and bandwidth that contribute the most to the
%network.
The expected \emph{DCMP} behavior as far as our $3$ criteria is:
%
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% It returns more result than LTM according to experiments in
% \cite{ZKB2008}
medium &
% Duplicates are an important fraction of the redundant overhead imposed by
% topology mismatch and thus DCMP minimizes this as possible.
% The control overhead is also one to two orders of magnitude less than LTM due
% to its ``lazy'' broadcasting of control messages (as opposed to LTM's periodic
% approach) - \cite{ZKB2008}
low &
% fully distributed method
high
\end{tabular}
}
\end{center}

%       CACHING

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Replication Strategies in Unstructured Peer-to-Peer Networks}

In~\cite{CS2002}, replication is used as a way to improve inefficient blind
search. As the number of replicas and/or cached copies increases in the network,
it would relatively easy to locate items even if search is random.
To analyze the feasibility of such an approach, \cite{CS2002} investigates
$3$ replication strategies: \emph{uniform}, \emph{proportional}, and
\emph{square root allocation}. In the uniform model, the copies of items are
uniformly spread over the network, while in the proportional, items are
replicated based on their query rate, so that frequently queried items can be
found more often.
The square root is a compromise between uniform and proportional allocation
models. The overall costs for both successful and unsuccessful
searches are compared to ascertain the effectiveness of the $3$ suggested 
approaches. Experimental outcomes indicate that the uniform allocation 
minimizes the maximum search length and so it can reduce the time spent on
unsuccessful searches. 
The proportional strategy effectively decreases the search time 
for popular items, but suffers when needing to locate the rare entities.
When it comes to expected successful search size, it is the same for 
for both uniform and proportional models and any approach in between 
to always behave much better. The square root allocation  aims at minimizing the 
expected search size for successful queries in \p\ networks.
The table below outlines how the $3$ strategies fare:
%%
\begin{center}
{\footnotesize
\begin{tabular}{rccc}
\multicolumn{1}{r}{} &
\multicolumn{1}{c}{\emph{Efficiency}} &
\multicolumn{1}{c}{\emph{Overhead}} &
\multicolumn{1}{c}{\emph{Scalability}}
\\
\cline{2-4}
\emph{Uniform Replication} &
% Proportional and Uniform are the worst “reasonable” strategies
low &
% When item is created, replicate its key in a fixed number of hosts.
low &
%
medium \\
\emph{Proportional Replication} &
% Proportional and Uniform are the worst “reasonable” strategies
low &
% for each query, replicate the key in a fixed number of hosts (need to know or
% estimate the query rate)
medium &
%
low \\
\emph{Square Root Replication Allocation} &
% All (strictly) in-between strategies are (strictly) better than Uniform and
% Proportional - replication theory
medium &
% Assuming that each query keeps track of the search size then each time a query
% is finished the object is copied to a number of sites proportional to the
% number of probes that the search required.
medium &
% e.g. path replication is easy to scale, just detect the path along which the
% query ultimately got fulfilled
medium \\
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Tracing a large-scale Peer to Peer System: an hour in the life
% of Gnutella}
% TODO: This looks better as an analysis for the unstructured networks in
% general and specifically for caching, so it doesn't seem to contribute any
% new approach.... At least we do not present anything here. Maybe we need to
% revisit the paper itself once more
% \cite{Markatos02} analyses Gnutella network traffic traces and by concluding
% there is locality among query requests, proposes a caching algorithm that tries
% to exploit these findings . The analysis of the trace data reveals other
% important facts about the structure of the Gnutella network and the query data.
% One significant observation is that the geographic locations of clients do not
% have a correlation with the number of query requests they receive. This is an
% obvious result of the topology mismatch problem caused by the overlay structure
% of the Gnutella network. Gnutella's traffic is observed to be bursty both for
% query requests and query responses, even in longer intervals. It is observed
% that a peer receives 50 query messages per second on average! Moreover nine out
% of ten queries do not generate any response due to the inefficient design of
% the Gnutella network. When developing a caching system to exploit locality,
% applying an approach similar to web caching does not fit well with P2P systems.
% Caches in P2P systems not only have to consider the query string, but also
% the TTL value, the source of the query, and the time of the query as well.  In
% general, even though optimum caching is hard to achieve, it is reported that
% it improves the overall performance of the Gnutella network.

% \begin{center}
% \begin{tabular}{ccc}
% \emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
% \hline
%
% ? &
%
% ? &
%
% ?
% \end{tabular}
% \end{center}


%       OVERLAY OPTIMIZATION

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Narada}

% \begin{figure}[ht]
% \centering
% \subfigure[Underlying network with edge costs.] {
%   \includegraphics[scale=0.4]{img/algorithms/narada}
%   \label{figure:narada:underlying}
% }\qquad\qquad
% \subfigure[Peer A sends a message to the rest using regular broadcast.] {
%   \includegraphics[scale=0.4]{img/algorithms/narada2}
%   \label{figure:narada:regu}
% }\qquad\qquad
% \subfigure[Peer A sends a message to the rest using end system multicast.] {
%   \includegraphics[scale=0.4]{img/algorithms/narada3}
%   \label{figure:narada:multicast}
% }
% \caption{A visualization of the Narada protocol.}
% \label{figure:narada}
% \end{figure}

{\sl Narada}~\cite{CRZ2000,CRSZ2001,CRSZ2002} is a generic
protocol for creating self-adapting overlay networks capable of 
application-layer multicast communications without requiring IP multicast
infrastructure at the network layer.
Although IP--multicast would present a choice in implementing
{\sl Narada}, it is in general considered that it violates the 
stateless design of the current Internet.
Despite the fact the {\sl Narada} was not designed as \p\ system per se,
it was the first (along with \emph{Scattercast} \cite{C2000}) to consider the
feasibility of overlay-based, application-layer services over the Internet while
taking into account bandwidth and latency properties of the underlying physical
infrastructure. In the context of this work, the inefficiency caused by the
topology mismatch and attempted to be tackled by building an highly connected
graph termed \emph{mesh}
with each source featuring its own minimum spanning tree. A gossip-protocol was
deployed for the creation of these spanning trees~\cite{LYL2008}.
%as shown in Figure~\ref{figure:narada}.
Both graph and trees are dynamically updated as nodes keep joining 
or departing the network. The protocol aims to ease the physical link stress,
the overall resource usage as well as the relative delay among end-systems. 
Unfortunately, the main limitation for {\sl Narada} is that 
although it works reasonably well for small groups, 
it does not scale well for larger networks. 
Hence, it is not a suitable choice for potentially large \p\ networks:
%%
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
%
medium &
% The overhead of Narada is proportional to the multicast group size
high &
% Maintaining the mesh for large multicast groups is expensive.
low
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Adaptive Overlay Topology Optimization (AOTO)}

Along with {\sl Narada}, the \emph{Adaptive Overlay Topology 
Optimization (AOTO)}~\cite{LZXN2003} is one of the first attempts to address the
topology mismatch problem. \emph{AOTO} is a distributed algorithm that seeks to
optimize the usage of the underlying physical resources and operates in
$2$ phases:
\emph{Selective Flooding} and \emph{Active Topology}.
In \emph{Selective Flooding}, a minimum spanning tree is built for each peer and
its immediate neighbors so that queries do not flood the entire network and at
the same time preventing their search scope from shrinking. This way some
neighbors become non--flooding. During \emph{Active Topology}, each peer
replaces independently such non--flooding neighbors, with closer nodes as an attempt
to revise the overlay links so that they can reflect more closely the physical
network topology. Picking a replacement out of these non-flooding
neighbors follows a random policy called \emph{Randomized AT} algorithm.
To accomplish the above actions, a peer has to keep track of 
its communication costs with all its neighbors (e.g., network delays)
as well as the costs between any pair of neighbors. The \emph{randomized AT}
algorithm is applied by a source peer
every time its neighbor list is updated or an updated neighbor cost 
table is received.
%%
%\paragraph*{Selective Flooding (SF)}
%
% TODO: I DON'T REMEMBER WHY THE FOLLOWING IS MENTIONING LTM WHICH IS ANOTHER
%       ALGORITM. MAYBE THIS CAN BE USED AS A PART OF DISCUSSION AND/OR
%       COMPARISON OF AOTO AND LTM
% TODO: EDIT: LTM SEEMS A MISTAKE HERE BETTER NOT USE IT FOR DISCUSSION (THIS
%             IS AOTO)
%LTM's SF effectiveness has be proven to be detached from the different physical
% or overlay topologies. On the other hand, SF is more effective with large
%number of logical neighbors. It can reach an average optimization rate of 87.4
%percent on a logical topology with an average of 30 logical neighbors.
%
%\paragraph*{Active Topology (AT)}
%
%Different numbers of average logical neighbors has little to do with the
% effectiveness of AT. If the source has $n$ non-flooding peers, there are $n$
%potential neighbor replacements. The overhead to exhaust all $n$ possible
%replacements can be high, so in practice, after each replacement the source
%peer can decide whether it needs to find another candidate peer. This is done
%by computing the cost improvement ratio greater than some predefined
%termination threshold. The larger the threshold, the slower, in the number of
%optimization steps, the reduction of the normalized average distance. As a
%whole the average response time is significantly reduced when more optimization
%steps taken.
%%
\emph{AOTO}'s performance regarding the $3$ criteria is as follows:
%%
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
%
medium &
% tracking of communication costs to all peer's neighbors as well as between
% any pair of neighbors. Whenever a new neighbor cost table is received or
% there is a change of neighbors, the source peer has to re-calculate the
% multicast tree and apply the randomized AT algorithm.
high &
% needs global knowledge
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Adaptive Connection Establishment (ACE)}
The \emph{Adaptive Connection Establishment (ACE)} 
approach~\cite{LZXN2004} uses the network delay as a metric 
to estimate the costs between nodes. Each peer computes the costs to its
logical one-hop neighbors and forms a \emph{neighbor cost table (NCT)} 
using a special routing message type. 
Any pair of neighboring peers exchange their \emph{NCT}s 
and so a minimal overlay topology can be formed. Based on the obtained
\emph{NCT}s a minimum spanning tree for each peer and its one-hop neighbors is
created. Finally, neighbors located physically far away 
are replaced by physically-closer counterparts. 
In particular, a peer $S$ iteratively probes the distance $d$ between
itself and every of its non-flooding neighbor nodes $G$ as well as
the distance between $S$ and $G$'s neighbors designated as $H$.
If $d_{SG} > d_{SH}$, then link $SG$ is replaced by link $SH$. If, on the other
hand, $d_{SG} < d_{SH}$ then also $d_{GH}$ and then we have the following
options. Either $d_{SH} < d_{GH}$ in which case link $SH$ is kept or
$d_{SH} > d_{GH}$ in which case $S$ will keep probing other $G$'s direct
neighbors.
%%%
The above optimization is conducted within $1$-neighbor
closure using as base, a peer and checking all its direct neighbors.
Evidently the scope of such an operation could be extended.
Should  a larger scope be used, a better topology matching can be obtained 
at a greater computational overhead.
%
% TODO: SOME DISCUSSION
%
%Simulations in \cite{liu_acesims_2004} show that the average scope of each
% query to cover the same scope of nodes is reduced by about 65 percent without
%losing any autonomy feature, while the average response time can be reduced by
%35 percent. Larger diameter topologies lead to better topology optimization
%rate but also to higher communication and computation overhead. It was also
%found that it is more effective in higher connectivity dense topologies.
%Compared to LTM, it comes short of convergence speed. In
%\cite{ni_mismatch_2004} shows reduction of both total traffic (90 percent) and
%response time (80 percent) to message queries without shrinking the search
%scope.Last but
%not least, it is concluded that work must be done on incorporating a more
%sophisticated selection policy for candidate non-flooding peers.
%

%In \emph{Adaptive Connection Establishment (ACE)} \cite{LZXN2004}, the
%authors extend the idea of AOTO by introducing optimizations based on the
%depths of the minimum spanning trees. But since the network delay is not
%always a reliable estimation method to detect the physical location of peers,
%the algorithm still suffers from the discrepancies caused by mis-located nodes.
%%
%%
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% compared to LTM it has slow convergence speed.
medium &
% A little bit better that AOTO since the computation here is done within a
% certain diameter from the source peer
medium &
% Larger diameter topologies lead to better topology optimization
% rate but also to higher communication and computation overhead.
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Location-aware Topology Matching (LTM)}

\emph{Location-aware Topology Matching (LTM)}~\cite{LLXNZ2004} 
seeks to optimize an overlay \p\ structure based on the physical topology.
To achieve this, peers issue special messages called
\textit{TTL-detector}s whose \emph{TTL} values are $0$ or $1$;
in this regard, peers 
discover $1$- and $2$-hop neighbor sets, designated as $N$ and $N^2$
respectively, and proceed to compute communication costs.
Time-stamps are used to derive network latency measurements that are then used 
to improve the overlay network without sacrificing the search scope.
Each node compares the latency information
received from its direct neighbors;
peers with longer latencies are placed on a
\emph{will-cut} list where they remain for a certain period of time 
after which they are finally eliminated 
and are placed on the peer's \emph{cut-list}. 
Thus, low-productivity connections are dropped and replaced by 
more efficient ones, reducing the
latency on the overall network. 
Although \emph{LTM} improves the overall efficiency of
the \p\ network, it is unable to offer any warranty for 
effectively addressing the mismatch problem.
%
% TODO: SOME DISCUSSION
%
%\paragraph*{Low productive connection cutting}
%There are three cases for any peer $P$ who receives $d(i, S, v)$ multiple
% times:
%\begin{inparaenum}[\itshape i\upshape)]
%  \item $P$ receives both $d(i, S, 1)$ and $d(i, S, 0)$
%  \item $P$ receives multiple $d(i, S, 0)$s from different paths, and P
% randomly chooses to process one
%  \item $P$ receives one $d(i, S, 1)$ and multiple $d(i, S, 0)$s, and $P$
% processes $d(i, S, 1)$ and one randomly selected $d(i, S, 0)$
%\end{inparaenum}
%If the link with the largest cost is found and is a direct neighbor then the
% connection is put in a will-cut list and stays there for a certain period of
%time. If it is not, then it is handled by other peers. After that period,
%connections are cut and recorded to $P$'s cut-list.
%
%\paragraph*{Source probing}
%For a peer $P\in(N^2(S) - N(S))$ who receives only one $d(i, S, 0)$, the cost
% of $PS$ is obtained (with list look-up or probing). Then $P$ compares it with
%the cost from each hop and if $PS$ has the largest cost, $P$ will not keep this
%connection, while otherwise the connection will be created.
%
%\paragraph{}
%Supposing $n$ is the number of peers, $c_n$ is the average number of neighbors
% and $c_e$ is the average cost of logical links, then in the flooding-based
%search the traffic incurred by one query from an arbitrary peer in a
%peer-to-peer network is $O(n)$. As observed in the Gnutella network
%\cite{sripanidkulchai_gnutella_2001}, each peer issues $0.3$ queries per minute
%in average, thus the per minute traffic incurred by the network with $n$ peers
%is $O(n^2)$. Because each $d(i, S, v)$ has a TTL of $2$ in each source peer,
%the traffic for one time LTM optimization in all peers is at most $2nc_n^2c_e$.
%If each peer uses LTM $k$ times per minute, the total traffic incurred is
%$2knc_n^2c_e$. Simulation shows the best value for $k$ is $2$ or $3$. So, the
%traffic overhead caused by LTM to the network is $O(n)$.
%
%TTLj-detectors, with $j > 2$, would detect and break cycles with more than 4
% links. LTM though, does not use such detectors because detector-flood traffic
%would increase significantly, and cut links between two end-peers, could cause
%queries initiated by them to traverse a path much more expensive than the cost
%on the the cut link.
%
%\paragraph{}
%LTM disadvantages are
%\begin{inparaenum}[\itshape i\upshape)]
%  \item disagreement of measured delay due to unsynchronized clocks causes
% problems when deciding the cut positions, which can influence the network
%connectivity, and
%  \item the network delay metric mainly focuses on disabling the connections
% between peers physically far away without considering the shortcuts created by
%powerful peers.
%\end{inparaenum}
%
\emph{LTM} fares as follows regarding our $3$  criteria:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% Authors claim 75% reduction on traffic cost and about 65% reduction on query
% response time.
medium &
%
medium &
%
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Scalable Bipartite Overlay (SBO)}

The \emph{Scalable Bipartite Overlay (SBO)}~\cite{LXN2004,LXN2007} 
reduces the overhead of creating
and maintaining a minimum spanning tree 
by randomly dividing the nodes into
two groups --\emph{red}s and \emph{white}s-- 
and assigning different tasks to the two groups.
When a peer joins the network, it is randomly assigned with an initial
color (red or white).
Then the network bootstrap host node furnishes the joining peer with a list
of active peers along with their color information. 
The joining peer uses this list to 
establish connections to differently colored peers. 
In this regard, all peers form a a bipartite overlay. 
Using the network delay as a metric, white-peers 
peers measure distances from red counterparts
and report the encountered red neighbors.
Having information on all their $2$-hop neighbors 
($N^2$)
red-peers create minimum spanning trees for the neighbors in question and
assign efficient $2$-hop forwarding paths. This process can render a white
peer $E$ non--forwarding neighbor of the red peer $P$. Direct neighbor
replacement is a process conducted by $E$ in order to replace $P$ with a
$P' \in N^2(P)$ as its new neighbor. This adaptation tackles the
topology mismatch problem by reducing message duplication and shorten response
times caused by the problem identified as \emph{Revisit Not known (RN)}. RN is
the situation when a node is visited some times as a relay stop before it is
visited as an overlay peer, thus creating duplicate unnecessary messages to the
network and delaying query responses.
%
% TODO: SOME DISCUSSION
%
%In a static environment LTM may reduce traffic cost by around 80 to 85 percent
% while SBO reduces traffic cost between 85 and 90 percent. However, LTM  is
%proved to converge in around 2-3 steps while SBO needs 4-5 steps. Moreover LTM
%reduces response time by more than 60 percent in 3 steps while SBO needs 8. In
%a dynamic environment (10 minute average peer lifetime, 0.3 queries/sec by each
%peer) SBO and LTM reduce the average traffic cost per query (including the
%overhead due to the optimization steps) by 85 and 80 percent, respectively.
%Moreover LTM reduces the response time per query to 30 percent while SBO to 35
%percent.
%
%\cite{ni_mismatch_2004} shows SBO, achieves approximately 85 percent reduction
% on traffic cost and about 60 percent reduction on query response time.
In regards to the $3$ stated criteria, \emph{SBO} behaves as follows:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% SBO reduces traffic cost between 85 and 90 percent
high &
% compared to LTM it has slower convergence speed thus incurs more, total,
% overhead.
medium &
%
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Two-Hop-Away Neighbor Comparison and Selection (THANCS)}

The distributed heuristic termed 
\emph{Two-Hop-Away Neighbor Comparison and Selection (THANCS)}~\cite{LNXE2005,L2008}
attempts to minimize overlay hop costs.
\emph{THANCS} is essentially a \emph{local search method} as it aims 
to find a locally optimum solution by exploiting knowledge within 
a $2$-hop radius. The algorithm consists of two main components:
\emph{piggybacking neighbor distance on queries} and
\emph{neighbor comparison and selection}.

The \emph{piggybacking component} requires peers 
to probe immediate neighbors using delay distance measurements 
and store information locally. The algorithm introduces a special query message
type, the \emph{Piggy Message (PM)} which includes information about 
the neighbor identification (IP) and measured distance ($d$). PMs are
piggybacked to normal
Gnutella messages. When node $P$ receives a query from $Q$ it constructs a
$PM_{PQ}$, piggybacks it to the query and forwards it to $P$'s neighbors. When
the neighbors recieve it they detach the $PM_{PQ}$, record the distance
$d_{PQ}$ and process the query normaly. Selection of which incoming queries
should be piggybacked with a \emph{PM} is proposed by either
\emph{pure probability-based (PPB)} or \emph{new neighbor triggered (NNT)}
policies.

The \emph{neighbor comparison and selection} component defines that a peer $S$
probe all his $2$-hops away neighbors (a set denoted as $ N^2(S)$) not probed
thus far. Let $P$ be a $1$-hop distance neighbor of $S$, and $Q$ be a probed
peer by $S$. When $S$ receives a message piggybacked with a $PM_{PQ}$ we
identify the following cases.
\begin{itemize}
  \item If $Q$ is already a direct neighbor of $S$ then we check the distances
  $d_{SQ}$, $d_{SP}$ and $d_{PQ}$. If either $d_{SQ}$ or $d_{SP}$ is the longest, then the longest
  link will be put in a \emph{will-cut} list\footnote{A peer will not send or
  forward queries to connections in its will-cut list but will preserve them
  for some time in order not to effect ongoing response messages travelling the
  inverse path.}. If $d_{PQ}$ is the longest then nothing is done by $S$; being
  fully distributed, neighbor comparison and selection process, will have the
  oportunity to handle $PQ$ link when initiated by peers $P$ or $Q$.

  \item If $Q$ is strictly a $2$-hop neighbor of $S$ and have never probed $Q$
  in the past, stores distance $d_{SQ}$ and checks distances $d_{SQ}$, $d_{SP}$ and $d_{PQ}$.
  If $d_{SQ}$ is the longest, $S$ will not create link $SQ$. If $d_{SP}$ is the
  longest, $SQ$ will be created and $SP$ will be put into the will-cut list.
  If $PQ$ is the longest, links $SP$ and $SQ$ will be preserved expecting that
  $P$ or $Q$ will disconnect $PQ$ later.
\end{itemize}

%
% TODO: SOME DISCUSSION
%
% \begin{inparaenum}[\itshape i\upshape)]
%   \item is completely distributed and needs no global knowledge,
%   \item presents trivial overhead compared to the query cost savings
%   \item its convergent speed of the algorithm is fast enough (faster than
% minimum spanning tree approaches) so that is effective to dynamic
% environments, and
%   \item does not shrink the search scope.
% \end{inparaenum}
%
%In a static environment THANCS has been proven to be effective; optimizing 45
% percent out of the 60 percent of mismatched paths, constructing a nearly
%optimal overlay. This leads to a 60 percent reduction in traffic cost as well
%as a 40 percent decrease in query response time. In dynamic environments
%(Gnutella 0.6/Limewire super-peer-like and Ion flat-like), THANCS saves up to
%70 percent of the traffic cost in the super-peer topology and 55 percent for
%the flat one. Average response time is also decreased by 60 and 45 percent,
%respectively. Generally, THANCS has similar performance to LTM, without needing
%synchronization. SBO, incurring half the  overhead of AOTO, reduces the traffic
%cost the most, while THANCS has lower response time and converges faster than
%SBO. THANCS is, thus, more suitable for a more dynamic environment. In
%addition, THANCS is easy to implement and its operation overhead is trivial,
%compared with the other three approaches. This design, however, has the
%limitation of not being easily extend to also support non-flooding-based
%systems.

As seen above, the method is fully distributed and needs only minimum knowledge
of, at most, a $2$-hop distant peers. This makes it a good candidate for big
overlay networks. Also topology adaptation helps construct a well fit overlay
network with restect to the underlying one (at least with respect to network
distances). Morever will-cut list and distance cache (which stores already
probed peers) minimize the unnecessary messages for the network maintenance.
These characteristics are depicted to the $3$ evaluation criteria we use in this
survey as follows:

\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% 
medium &
% trivial overhead compared to the query cost savings and its convergent speed
% is faster than minimum spanning tree approaches so less overall overhead cost.
low &
% completely distributed and needs no global knowledge,
high
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The \emph{Hops Adaptive Neighbor Discovery (HAND)} algorithm~\cite{CLZHC2006}
uses a fully-distributed triple--hop adjustment strategy, applied to a network
graph $G$ in order to create an optimal graph $G^{*}$, free of the implications
of topology mismatch. This optimality is attained if all peer hop 
sequences $(v_1, v_2, \ldots, v_k)$ of $G$ exist in $G^{*}$ and are in the same
order. The latter indicates that in practice triple sequences $(v_1, v_2, v_3)$
are used. A mismatch is detected as follows: supposing that we want to verify
a sequence, say $v_2-v_1-v_3$, two probing messages are dispatched from $v_1$ to
$v_2$ and $v_3$ and yield delays of $x$ and $z$ respectively.
%
When the probing message arrives at $v_2$, it gets forwarded
directly to $v_3$. 
Similarly, the message reaching $v_3$, it is directly forwarded to $v_2$.
The above two forwarding actions seek to quantify 
the corresponding delays of $(v_2,v_3)$ and $(v_3,v_2)$ physical paths
denoted by $y$. 
%%
If $y=z-x\pm\varepsilon$, the sequence $v_2-v_1-v_3$ is mismatched and should
be adjusted to $v_1-v_2-v_3$ by deleting edge $(v_1,v_3)$ and 
then adding a new $(v_2,v_3)$. 
If $y=x-z\pm\varepsilon$, sequence $v_2-v_1-v_3$ is mismatched and
should be adjusted to $v_1-v_3-v_2$ by deleting edge $(v_1,v_2)$ and adding a
new $(v_3,v_2)$. 
The  $\varepsilon$ is a small positive real number denoting
additional delays caused by possible forwarding and jitter delays. 
%%
The advantages of \emph{HAND} are that it
\begin{inparaenum}[\itshape i\upshape)]
  \item does not need any clock synchronization,
  \item is a fully distributed algorithm.
  \item involves low traffic overhead,
  \item can be used in dynamic \p\ environments, and 
  \item furnishes low query response times.
\end{inparaenum}
%
% TODO: SOME DISCUSSION
%
%Measurements conducted for evaluation purposes showed that in a static
% environment the algorithm can effectively decrease traffic cost by about 77
%percent and shorten the query response time by about 49 percent in less than
%two minutes. In a dynamic environment it shows similar behavior and with the
%size of the overlay network having little impact on the effectiveness of the
%algorithm. Compared to LTM both algorithms have almost the same traffic
%reduction rate, however on the response time reduction rate HAND has a higher
%one by about 4 percent. The traffic overhead of HAND is much less than that of
%LTM by an average of 55 percent.
In terms of the $3$ stated criteria, \emph{HAND} fares as follows:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% similar traffic reduction rate savings to LTM
medium &
% The traffic overhead of HAND is much less than that of LTM by an average of
% 55 percent.
low &
% no clock syncing needed, fully distributed and with low control overhead the
% algorithm can be considered scalable.
high
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Adaptive Peer Selection (APS)}
The \emph{Adaptive Peer Selection (APS)} approach uses 
machine learning techniques to form peer selection strategies based on past
experience~\cite{BFLZ2003}. A decision tree is used to rate peers based on
information collected for the characteristics of established connections. Such
features include connection link load, bandwidth, and past uploading experience.
Subsequently, a Markov decision process is introduced as a mechanism to shape
the policy for switching among the peers. The success of approach depends on
how fast the introduced peer selection functions. Admittedly, \emph{APS} is slow 
due to the learning process and its inherent complexity. As far as the $3$
criteria is concerned, \emph{APS} has as follows:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% machine learning the best way to adapt the overlay 
high &
% high computation overhead for learning and very slow convergence speed for
% the learning process.
high &
% Complexity of computation, and slow convergence speed prevents the approach
% to scale, especially in high churn environments.
low
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The \emph{Innocuous Topology Aware Overlay Construction (ITA)}
approach~\cite{PRFM2009} seeks to offer both an overlay formation approach and
an effective way to carry out searching. When constructing the overlay,
\emph{ITA} exploits the notion of \emph{short} and \emph{long} connections.
Should $N$ be the number of network peers,  $\alpha \leq 1 $ a system-wide magic
number and $x$ an $\alpha$-related latency threshold, the bootstrapping peer
randomly selects $\alpha \ast N$ ``close'' (latency below $x$) and 
$\left( 1 - \alpha \right) \ast N$ distant (latency above $x$) nodes
as its neighbors.
%%AD how do they select all these magic constants???
%%VM This α constant seems to be the percentage of close neighbours selected by
% a peer out of its total degree. Can't find the criterion with which it is
% chosen though. Maybe we can ask... Mema :)
Searching occurs in two phases: in the initial phase, the querying node
floods its distant neighborhood  with $TTL = 1$.
Subsequently, peers receiving a query over a ``long link'' commence a 
local flood with $TTL=ttl$ where \emph{ttl} is system-defined.
%%AD how are you supposed to define these params?? in a fixed manner??
%%
%% VM Don't understand... the paper says that for increased awareness we need a
%% small α (page 7). But in the begining they give that short links (close-by)
%% are given by α*Ν. I guess this gets smaller for smaller α.... Also on
%% page 7 they say they choose α to be 0.1, 0.05 and 0.033 and that
%% this equals to ``10, 20, 30 long and and the same number of short links''.
%% I don't understand how they deduce these numbers. Since short links is given
%% by α*Ν and long by (1-α)*Ν at least the numbers should be different from
%% short and long links...
The main objective of the overlay construction phase is to yield a network that
exhibits low clustering. In turn, this is a beneficial characteristic for
random graphs as it can lead to a larger coverage of peers and at the same time
helps reduce duplication of messages travelling around the network. This
combination offers efficient lookups that pose minimal or no negative impact to
other mechanisms possibly employed by the \p\ systems (e.g., 1-hop replication
or dynamic querying mechanisms).
A 50\% reduction in communication latency among peers by cutting off 
some 20\% of the \emph{IP}-level traffic generated 
in reported in~\cite{PRFM2009}.
%%
\emph{ITA} places as follows in the context of the $3$ criteria:
%
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% low clustering with larger coverage of peers with the same number of messages
% and reduced duplication.
medium &
% construction at peer join, while searching using local ``floods''
low &
% the selection of neighbors is done at join time. No overlay adaptation means
% low scalability in dynamic environments.
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{EGOIST}
\emph{EGOIST}~\cite{SLLBBR2008} is a set of algorithms 
to construct and manage overlay networks. 
\emph{EGOIST} utilizes a selfish approach in the sense that every participating
peer continuously updates its neighbors so as to minimize the sum of distances
to all destinations under shortest-path routing. 
A newly arriving peer, randomly connects to an already participating 
node through a bootstrap server. Once connected, the peer starts receiving
information throughout the link-state mechanism and thus, after some time, 
it has a complete picture of the overlay graph. 
Then the peer estimates the delay to all other nodes to
determine its potential neighbors and ultimately connects 
to the overlay using some policy; such a policy might be 
for example the minimization of the average delay to all its
neighbors. \emph{EGOIST} requires extensive resource usage to continuously
update the overlay connections of all the nodes in the system. This needs
$O(n^2)$ measurements. Fortunatelly, each node does not need to do these
measurements for maintenance (monitoring and updating) with all other
participating nodes, but just with a number of $k<n$ nodes that it chooses to
establish links with. This gives a reduced $O(kn)$ time complexity for
maintenance while $O(n^2)$ is needed less frequently, when nodes reevaluate
their connections.

Regarding the $3$ criteria, \emph{EGOIST}'s behavior is as follows:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% peer neighborhood selected to minimize, for example, average delay
high &
% link state info (heartbeat) and delay estimation to all other nodes
% resulting to a complete picture of the overlay graph.
high &
% need global knowledge
low
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The main objective of the \emph{Biased Neighbor Selection (BNS)} 
approach~\cite{BCCMSBZ2006} is to 
strengthen {\sl BitTorrent}'s~\cite{c_bittorrent_2003} locality 
by carefully choosing most of the neighbors of a peer to come from 
the same \emph{ISP}, while at the same time adhering to the near-optimal
download performance of the protocol.
%%
By and large, {\sl BitTorrent} deploy mechanisms that have proved
aggressive for \emph{ISP}s' networking and accounting as they function 
in a ``without-borders'' approach. The default {\sl BitTorrent} specification
designates $35$ connections for each peer regardless if such connections are
placed within or outside the borders of the \emph{ISP} that hosts the node.
%%
\emph{BNS} proposes that only $k$ out of these $35$ connections are 
established with nodes beyond the {\it ISP}-borders;
the $k$ connections offer an extended and ``global'' view of 
the network at large and seek to strike a balance between 
the load imposed inside and outside the \emph{ISP}.
The latter refrains peers from exchanging traffic through
expensive network links should there exist alternative local connections
offering the sought services. 
\emph{BNS} is realized either through 
the modification on the tracker so that \emph{ISP}-local resources are rapidly 
identified,
or through \p\ traffic shaping devices installed on \emph{ISP} edge routers. 
%%
In~\cite{BCCMSBZ2006}, a combination of 
biased neighbor selection along with bandwidth throttling
and caching techniques for near-optimal lookup results is proposed.
Unfortunately, \emph{BNS} deployment requires knowledge of 
\emph{ISP} network mappings and awareness of possible changes 
that occur in the infrastructure limiting its widespread adoption;
the following table qualitatively depicts the expected behavior of \emph{BNS}:
%%
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% inter-ISP cost minimized while retaining the near optimal performance of
% BitTorrent download.
high &
% this info is taken at swarm join
low &
% trackers should maintain and update proximity info/proximity info is
% retrieved from special hardware.
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\emph{Ono}~\cite{CB2008} is a protocol that helps contain
{\sl BitTorrent} traffic within individual \emph{ISP}s
and enhances the downloading rates by favoring connections
within the borders of a single autonomous system. Contrary to
\emph{BSN}~\cite{BCCMSBZ2006},
\emph{Oro} leads to improved performance 
without requiring any explicit cooperation between 
\emph{ISP} subscribers or any additional
infrastructure and network topology information.
\emph{Oro}'s selection approach is 
landmark-based and leverages existing {\sl CDN}-infrastructure 
for peer distance estimation. {\sl CDN}s already use both static (i.e.,
geographical, IP-clustering) and dynamic (i.e., network delay measurement)
information for their replica selection. Thus, the algorithm leverages the
observation that peers that are redirected to a specific CDN replica does not
only mean that these are close by this replica but to each other as well.
%%
The redirection behavior is modeled in terms of \emph{ratio map}, 
a vector of \emph{$<$replica-server,ratio$>$} tuples, where \emph{ratio} is
the percentage of times the {\sl CDN} redirects the peer 
to the specific \emph{replica-server}.
%%
The protocol's bootstrapping phase consists of the newcomming peer performing
{\sl DNS} lookup to {\sl CDN}-names to build its redirection information.
%%
Initially, the {\sl DNS} polling interval is set to $30$ seconds 
and increases by $1$ minute every time redirection information 
to the {\sl CDN} remains unchanged after the lookup.
The {\sl DNS} polling interval is halved if pertinent 
redirection information has changed.
To avoid the bootstrapping phase when the \emph{ratio map} 
is sufficiently fresh, 
\emph{Oro} persists the map after the end of a BitTorrent session.
%%
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% Authors claim minimization of inter-ISP traffic cost while enhancing the,
% already, near optimal performance of BitTorrent download.
high &
% periodic DNS lookups and CDN redirection imposes medium control overhead to
% the method.
medium &
% the use of CDNs make the approach not fully distributed thus less scalable
low
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Locality-Awareness in BitTorrent-like P2P Applications}
Three approaches that ``inject'' locality awareness 
in {\sl BitTorrent}-like applications are discussed in~\cite{LCLX2009}. The
first \emph{macroscopic-level} approach
focuses on improving the neighbor selection process. 
When a peer asks a tracker to join, 
the later sorts its swarm peers according to
their hop-count distance from the requesting peer 
send out the top-$k$ list of nodes (e.g., $k$=$50$).
%%
The second approach, applied in an \emph{intermediate-level}, manipulates the
{\sl BitTorrent} chocking/unchocking mechanism. A peer unchockes its $4$
closest in terms of 
% VM I put ``autonomous system'' back in again because in the context of this
% paper we are dealing on the number of AS crossings (one-hop = one AS crossing)
% untli we reach a neighbor.
Autonomous System
hop-count interested neighbors. 
The same applies also when the peer turns to 
the seeding state;  this  \emph{intermediate-level} approach favors
least distance and is in contrast to the original {\sl BitTorrent} 
implementation which favors uploading speed.
%%
Finally, the third approach that operates at 
a \emph{microscopic-level}, substitutes the rare-first chunk picking of the
original {\sl BitTorrent} protocol that picks the rarest of the available
chunks to download next, with a locality-first policy which picks first the
chunck that is closer. The distance value of a chunk is computed as the mean
value of the distances of the peers that posses it.
Through experimentation on a real-world Internet topology simulated on
PlanetLab, the locality-based approach achieves traffic optimization.
Nevertheless, it does not do that well when compared with the
random approach of the standard {\sl BitTorrent} protocol.

All methods target in exposing the locality of the basic functions of the
BitTorrent protocol. Even though they do not restructure the network to map
better to the underlying infrastructure they favour the intra-AS communication
over inter-AS communication thus reducing the general cost of communication.

\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% minimization of inter-AS traffic but unfair among peers.
medium &
% info (AS hop distances) acquired at swarm join
low &
% does not result in a better map to the underlying topology, it just eases
% the implications of complete locality unawareness.
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{TopBT}
\emph{TopBT}~\cite{RTLCGZ2010} seeks to enhance 
proximity awareness in the {\sl BitTorrent}
without the need of any additional infrastructure. The key conjecture upon
which \emph{TopBT} is built is that
a good peer selection metric should take into account both the
downloading speed and the network topology. 
In this context, the approach suggests a metric that designates
peers demonstrating high download rate, low reciprocal upload demand 
and low routing hops.
The metric is defined as the ratio of download to upload rate ${d}/{u}$
divided by the either the link-level $l$ or the number of routing hops required $a$.
This metric should guarantee selection of peers with high download rate, low
reciprocal upload demand and decreased routing hops.
The above \emph{TopBT}-metric is applied in various
aspects of the original {\sl BitTorrent} protocol to ``inject'' topology
awareness for improved peer selection. 
%%
In an effort to essentially improve on the inherent topology mismatch problem,
\emph{TopBT} modifies the peer list the tracker returns when someone first tries
to connect to the swarm, the initial connection establishment, and the
unchoking mechanism in the {\sl BitTorrent}. The important feature of TopBT is
that it does not need wide deployment of its same types in order to see results.
It also supports both link-hop and AS-hop metrics to identify proximity in
different levels.
%
%A peer that runs the TopBT protocol evaluates its neighbors by periodically
%emitting pings or trace-routes in order to unchock those peer that exhibit less
%hops to reach and higher download rates. \emph{Link-hops} are measured by using
%the TTL value that the originator receives as a response from the remote
%peer\footnote{Initial TTL values are known for the different operating systems
%(e.g. 64 for Linux or 128 for Windows NT/2000/XP) so the originator can
%calculate the hops using the value of the TTL on the response message it
%receives.}. Also the peer, when off-line, builds a table that maps IPs to
%\emph{AS-hops}, using BGP dumps.
%%
Through experimentation on hundreds of {\it PlanetLab} and residential hosts,
\emph{TopBT} offers more than 25\% traffic reduction and 15\% faster downloads
if compared with popular {\sl BitTorrent} implementations.
In reference to the stated $3$ criteria, \emph{TopBT} fares as follows:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% it takes into account both dl speed and network topology. The later though is
% rather coarse grained since it is taken into account on the AS level.
medium &
% the algorithm does not involve extensive calculations.
low &
% Does not need infrastructure and the calculations are distributed so it can
% scale
high
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Underlying Topology-Aware Peer Selection (UTAPS)}
The \emph{Underlying Topology-Aware Peer Selection (UTAPS)}~\cite{LCY2008}
is an effort to furnish an enhanced peer selection strategy. \emph{UTAPS}
essentially works in two stages: in the first,
it collects information to develop a picture of the underlying topology 
and in the second, it proceeds to make the peer selection based on 
this knowledge. In the first stage, \emph{UTAPS} employs
network tomography, a technique that probes from a large network's 
endpoints to infer its internal characteristics~\cite{chny_tomography_2002}. 
%%
Upon arrival of a new peer, the tracker trace-routes 
it to obtain some basic knowledge 
including IP address, routers involved, \emph{RTT} and number of 
hops traversed.
The more the peers in the swarm the better 
picture a tracker has for the underlying infrastructure.  
The tracker provides this information to the newcomer in the form
of the bootstrapping peer list. These newly joined peers traceroute the tracker
peer list themselves and return back to the tracker in order to further enhance
the tracker's view of the infrastructure.
%%
In the second stage, \emph{UTAPS} employs a set of heuristics
which target those peers that expose low \emph{RTT} and are found within
certain hop-counts away from
the routers observed during the initial traceroute.

It is reported in~\cite{LCY2008} that peers running \emph{UTAPS}
instead of the random peer selection, achieve better downloading rates
and at the same time offer reduced burden on the underlying \emph{ISP}s. 
\emph{UTAPS} stands as follows in regard to the $3$ criteria:
%%
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% coarse grained approach of the network tomography doesn't provide a detailed
% picture of the underlying network that the peers can then exploit
medium &
% trace-route and hop counts and calculation from both the tracker and the peers
% (the later for all peers in the bootstrapping list) increases the control
% overhead of the approach.
medium &
%
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{An Effective Network-Aware Peer Selection Algorithm in
% BitTorrent}
A clustering approach that differentiates peers encountered in a swarm
in those that are local, intra-\emph{ISP} and inter-\emph{ISP} is 
presented in~\cite{QLZG2009}.
The classification is carried with the help of the core routers used 
while peers communicate with the tracker. It is assumed that even though the
network may be highly volatile, these core routers are are usually more stable.
For this, a newly arriving
{\sl BitTorrent} peer, trace-routes the tracker and stores vectors containing
info like the IP address and the hop number of a traced router, as well as the
link delay of the traced router and the previous hop along the trace-route path.
These vectors are reported to the tracker and the latter uses this information
to classify the router through a $k$-means classification algorithm, with $k = 3$. 
For peer selection, \cite{QLZG2009} proposes a biased approach 
where the tracker returns $c$ close peers 
and $d\;=\;N-c$ distant peers, where $N$ is the length of the returned list. 
In choosing $c$, the tracker employs an iterative search process
first in the peer's local neighborhood. If not sufficient number of 
peers are available there, the tracker goes to intra-\emph{ISP} 
and subsequently, if needed, to the inter-\emph{ISP} cluster. 
%%
Experimentation in a controlled environment indicates up to
5\% faster downloading times as well as up to 22\% reduction of 
the total cross-\emph{ISP} traffic.
This clustering approach fares as follows in regard 
to the $3$ criteria:
%%
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% It incorporates clustering of peers to inter- and intra ISP which is a
% rather coarse grained method.
medium &
% only on peer arrival proximities to routers are estimated and sent to the
% tracker. Even though the tracker is backing the identification of a peer
% being close or distant the actual computation is done in a distributed manner
% thus not incurring too much additional controlling overhead.
medium &
% TODO: how intensive with regards to computing power is an on-line k-means
% (with k=3) classification???
% VM: do we have an idea?
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Peer-exchange Routing Optimization Protocols (PROP)}
In~\cite{QCYCZ2007}, two protocols termed 
\emph{Peer-exchange Routing Optimization Protocols (PROP)} 
are introduced to help adjust the neighborhood graph of an overlay network
while aiming at reducing the network's overall link latency.
\emph{PROP} algorithms are weaved around the concept of
``exchange'' of neighbors among peers; 
this is carried out so that participant node can collectively 
benefit from the attained reduction in network delays. 
%%
This ``collaboration'', is what differentiates this approach 
from others by allowing two peers to optimize
their neighborhood environment, than simply letting each node to ``selfishly''
choose its own strategy. 

%%
%% VM ADDING SOME OPERATIONAL DETAILS BELOW.
The PROP algorithms operate, basically, into two phases. During the \emph{warm-up}
phase a node $u$ probes its neighbors to collect distance information. Then it
contacts, at a fixed time rate $timer$, a random node $v$, $nhops$ away from it. New distance
information is calculated independently by nodes $u$ and $v$, now for the
hypothetical state when the potential exchange would occur. If the benefit
gained, in terms of reducing the average distance among the peers involved, is
above some predefined threshold then the exchange will actually occur,
otherwise no further action will be taken. The \emph{maintenance} phase, on the
other hand, differs from the warm-up one, in that the probability
of peers to be probed and the $timer$ interval that this happens, now depends on
past peer exchange results.

In the generic form of the \emph{PROP-G} protocol, a peer can exchange all of
its neighbors with those of another peer. This essentially results in the two
nodes exchanging positions so the topology and connectivity of the overlay is
not affected by the operation of the algorithm. The optimized version
\emph{PROP-O} permits peers to exchange selected sets of their neighbors. It is
not allowed to exchange neighbors allong the path of the nodes that perform the
exchange in order to ensure that in the end of the process the peers will remain
connected. Additionally, the algorithm needs to preserve the characteristics of
the network (i.e., the graph remains connected, preserve the degree of the
nodes), so the exchange always involves equal number of neighbors.

The following table depicts the behavior of the \emph{PROP} 
algorithms regarding the stated criteria:
%%
\begin{center}
{\footnotesize
\begin{tabular}{rccc}
\multicolumn{1}{r}{} &
\multicolumn{1}{c}{\emph{Efficiency}} &
\multicolumn{1}{c}{\emph{Overhead}} &
\multicolumn{1}{c}{\emph{Scalability}}
\\
\cline{2-4}
\emph{PROP-G} &
% The authors show that an Internet-like underlying physical topology has much
% better performance
medium &
% Exchanging neighbors within a radius of 2 (TTL value) reduces stretch
% significantly, while keeping the additional overhead at reasonable levels
low &
% The effectiveness of the scheme is reduced while the system size becomes
% larger, but as the number grows, this reduction becomes smaller
medium \\
\emph{PROP-O} &
% The algorithm can better reclaim the heterogeneity of peers (those with faster
% response) to reduce the system's aggregate delay. 
medium &
% Same as above
medium &
% The queries are directed through fast nodes so it is important such nodes
% be part of the network
medium \\
\end{tabular}
}
\end{center}

% TODO: SOME DISCUSSION
% PROP-G can be applied to both structured and unstructured overlays.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Resolving the Topology Mismatch Problem in Unstructured
% Peer-to-Peer Networks}
% TODO: to be reviewed

% In \cite{hsiao_redblue_2009}, Hsiao et al, claim to construct topology-aware
% unstructured overlays that \emph{guarantee} performance qualities in terms of
% \begin{inparaenum}[\itshape i\upshape)]
%   \item the expected communication latency among any two overlay peers
% regardless of the network size, and
%   \item the broadcasting scope of each participating peer
% \end{inparaenum}
% . The algorithm constructs an undirected graph $G = \left( V, E \right)$
% comprised by two subgraphs. The first, namely $G^{\left( red \right)} = \left(
% V^{\left( red \right)}, E^{\left( red \right)} \right)$ in the paper's context,
% includes all vertices of $G$ and ensures the connectivity of the graph by
% securing at least one path between any two nodes. In contrast, $G^{\left( blue
% \right)} = \left( V^{\left( blue \right)}, E^{\left( blue \right)} \right)$,
% contains those vertices of $G$ that have free edges to link to other nodes and
% because these are fully utilized, the following also stands $E = E^{\left( red
% \right)} \cup E^{\left( blue \right)}$. A joining peer $u$, partitions its
% neighbors into two subsets, the $B_u^{\left( red \right)}$ and $B_u^{\left(
% blue \right)}$. In order to populate the $B_u^{\left( red \right)}$ subset, peer
% $u$ samples peers uniformly and at random. Then, each of these selected peers
% discovers a routing path starting from itself towards the node with the smallest
% (or the largest) ID in the system.

% TODO: CHECK ONCE AGAIN
% \begin{center}
% \begin{tabular}{ccc}
% \emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
% \hline
%
% ? &
%
% ? &
%
% ?
% \end{tabular}
% \end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% \subsubsection{Distributed Domain Name Order (DDNO)}
The \emph{Distributed Domain Name Order (DDNO)} approach~\cite{Z-YK2005} 
uses domain names to detect topologically-close nodes.
The fundamental assumption of the approach is the nodes found in 
the same domain are also topologically close.
%%
\emph{DDNO}'s outcome is a flat overlay topology which, with some adjustments, 
can be utilized in super-peer architectures as well. According to the algorithm,
half of the possible connections of a node are used to connect to local peers
(called \emph{sibling} connections) and rest are used to randomly
connect to the peers anywhere on the network (called \emph{random} connections).
The former ensure the reduction of long distance traveling for messages, while
the later secure the connectivity of the structure and prevent network
partitioning.
%% VM NEW ATTEMPT TO EXPLAIN THE ALGORITHM
Upon arrival the newcomer peer $n$ asks a \emph{host-cache} to establish its
random connections. For establishing its sibling connections, the newcomer
multicasts a specialized \emph{message} $l$, to locate the right candidate(s).
Initially, the behaviour of this message, is modeled as a random walker,
until $l$ reaches some peer $d$ capable to guide it through its next step.
This capability is enabled through a \emph{ZoneCache}, a data structure that
contains information for nodes accessible in an $r$-hop radius from $d$.
Ultimatelly $l$ will reach a node $m$, candidate to become $n$'s sibling. $m$
will issue a broadcast message to its own siblings and then all togeather will
inform the initiating peer $n$ of who is willing to accept new connections.

The population and maintenance of ZoneCaches across the network is an important
task for the efficiency of the constructed overlay. While seeking to address the
mismatch problem, \emph{DDNO} is a heuristic approach that uses
\emph{Split-Hash} and \emph{dnMatch} algorithms to effectively encode domain
names and determine domain locality respectively. In terms of the $3$ criteria,
\emph{DDNO} fares are follows:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% Clustering approaches reduce search scope (or at least increase search
% satisfaction time). The algorithm tries to ease this problem by allowing some
% connections to be random
medium &
% overhead of split-hash and dnMatch is of low cost (TODO: double check this).
% Walker message is multicasted only when sibling connections must be
% established.
low &
% it can be utilized in hierarchical architectures as well meaning increased
% scalability. Tests show that an increase from 5K- to 10K-node system slightly
% increases the average hops needed to satisfy a lookupDN message.
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Critical Topology-Aware Grouping (CTAG)}
The \emph{Critical Topology-Aware Grouping (CTAG)} approach~\cite{ZL2006}
advocates a grouping strategy of peers based on the 
\emph{Internet Assigned Numbers Authority (IANA)} and 
the respective \emph{Regional Internet Registry (RIR)}'s IP assignments.
%% VM CHANGED DESCRIPTION
Based on these assignments, nodes that belong in the same 
organization are always addressed from the same block of IP addresses.
\emph{CTAG}, exploits this observation to construct topology-aware unstructured
overlays. On top of this, \emph{Adjacency Measurement (AM)} is proposed, as
a technique which uses the longest matching \emph{IP} segment criterion to
compute node proximity. \emph{CTAG} focuses on both the construction of the
overlay as well as its constant and dynamic adaptation.
In the first phase,
called \emph{bootstrapping grouping},
the {\sl Gnutella} web caching mechanism
is modified so that a newcomer may choose the closest, in terms of AM,
cache to retrieve the bootstrapping list. Similarly, during the second phase,
called \emph{dynamic revision}, the standard connection establishement mechanism
is also altered so that nodes with the highest AM metric are chosen. When a node
reaches its maximum number of neighbor
connections, it disconnects those neighbors with the lowest AM.
\emph{CTAG} behaves as follows regarding the $3$ criteria:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% The technique partitions the system reducing the search efficiency
low &
% IP-based clustering involves low overhead
low &
% Has average scalability mainly to its low overhead. In larger applications the
% clustering of the system prevents the system from scaling smoothly.
medium
\end{tabular}
}
\end{center}

%###############################################################################
%###############################################################################
%###############################################################################
%       LANDMARKING
%###############################################################################
%###############################################################################
%###############################################################################


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Landmark Binning (LM)}\label{sec:landmark_binning}
% \begin{figure*}
% \centering
%   \includegraphics[scale=0.4]{img/algorithms/landmark_binning}
% \caption{Example 2D coordinate overlay and a sample routing path from node D to
% (x,y).}
% \label{fig:landmark_binning}
% \end{figure*}

\emph{Landmark Binning}~\cite{RHMKS2002} partitions close-by nodes 
into bins based on their distance from well known anchor nodes across the
Internet.%, as shown in Figure~\ref{fig:landmark_binning}.
To detect locality, peers mainly use network latency (i.e. \emph{RTT}).
%  as a measurement technique. 
Despite the fact that such delays are not always accurate,
they are used in~\cite{RHMKS2002} for they are 
non-intrusive, transparent and easy to apply.
%%
For the binning to work, a few anchor servers with known
physical locations need to be installed in strategic positions 
across the the Internet. 
It is conjectured~\cite{RHMKS2002} that $12$ such servers can prove
sufficient for the task.
An arriving node measures its distance from these landmarks
and unilaterally decides to join a specific bin based on its measurements.
Specifically, the node measures its round-trip time to each of the landmarks and
orders the resulting \emph{RTT}-values in a decreasing order. 
%%AD I do not understand what the following sentence says..
%%	for each peer there is a different bin right?
%
%The ordering represents a \emph{bin},
%in the sense of close-by nodes having the same landmark ordering and hence
%belong to the same bin. 
%
%% VM I CHANGED THE ABOVE AS BELOW TO REPHRASE IT.
Each permutation of the set of landmarks represents a specific bin. Should there
$m$ landmarks be adopted, potentially $m!$  different bins exist. Peers that
end up with the same such ordering, belong to the same bin, in the sense that
if they experience similar overall latencies from fixed network points then it
is very likelly that they are close to each other.
%%
The operation of the method is independent of the model 
incorporated by the overlay network and thus it can be
applied with no significant changes to 
both structured and unstructured \p\ systems.
%%
The main disadvantage of the approach is that 
landmark servers must be installed and maintained throughout the world.
Provided that a \p-system often may have a few million nodes 
connected at any given point in time, landmark servers do 
inherently play a pivotal role in the operation of the network.
Although latency estimation does not drain network resources,
the scale of the approach does call for an alternative design.
In this respect, \cite{RHMKS2002} advocates the replacement of 
each landmark server by a cluster of servers.
However, this approach may not entirely avoid the creation of 
excessive network traffic flow through its landmark server-clusters.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%
%To answer the question as to whether the algorithm actually contributes
% positively to the construction of an enhanced overlay, the paper defines the
%\emph{gain ratio} as the factor by which the latency reduces when someone
%communicates with a random node from the same bin than with one not in the bin.
%This is implemented with an inter-bin to an intra-bin latency ratio.
%
% TODO: LANDMARK BINNING FOR UNSTRUCTURED OVERLAYS
%
%For unstructured overlays the paper assumes \emph{a set of $n$ nodes where each
% node picks any $k$ neighbor nodes so that the average routing latency on the
%resultant overlay is low (assuming shortest path routing)}. According to the
%proposed heuristic algorithm called \emph{BinShort-Long}, a node picks its
%neighbors by choosing its $\frac{k}{2}$ closest\footnote{If the node's bin is
%not large enough for it to pick these $\frac{k}{2}$ neighbors, it picks the
%required nodes from the bin that matches the most in terms of landmark
%ordering.} ones (named \emph{short links}), using the \emph{binning} scheme and
%the rest $\frac{k}{2}$ randomly (\emph{long links}). The former set produces
%well-connected \emph{pockets} of nearby nodes while the later preserves the
%connectivity of the graph, both yielding a proximity factor of $\alpha = 0.5$
%in an attempt to preserve the beneficial properties of unstructured
%topologies\cite{merugu_str2unstr_2003}.
%
% TODO: SOME DISCUSSION
%
%A potential bottleneck could be the extra load that this
%``ping''-like scheme imposes to the landmarks, especially when we need instant
%reaction from our topology when dealing with the dynamic nature of the p2p
%networks.
%
%One disadvantage of this landmark scheme is related to the additional burden
% imposed to the landmark sites. The authors claim though that the algorithm
%requires so little work by the landmarks (maybe just echo to ping messages)
%that could in effect, act as ``unsuspecting participants''. Even if this is the
%case, the fact that it is not fully distributed, renders the protocol's
%scalability directly vulnerable to any system size increase as well as
%suitable for highly dynamic networks such as ad-hoc networks. Moreover, fixed
%points in a network are inherently more exposed to malicious attacks. The most
%significant downside of the algorithm though is that it can lead to an
%extremely uneven overlay ID distribution causing load unbalances and hot spots.
%Lastly, the scheme is coarse grained when it comes to distinguishing relatively
%close nodes\footnote{In the worst case, all nodes could ve clustered into a
%single bin.}.
%
%%
The landmark binning behaves as follows:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% The technique is coarse grained thus doesn't achieve optimal results
% (especially in small networks)
medium &
% The algorithm needs only nodes to compute distances to a small number of
% predefined nodes without exchanging any additional information.
low &
% The introduction of landmark servers renders the approach not fully
% decentralized, thus preventing it from scaling smoothly. Communicating
% and overloading landmark servers in high-churn systems is another scalability
% concern.
low
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{mOverlay}
The \emph{mOverlay} \cite{ZZZSZ2004} approach addresses scalability issues
that might arise when static landmark servers are in use.
To this end, the use of dynamic landmarks is proposed.
\emph{mOverlay}'s founding notion is that of a \emph{group} that 
designates a set of peers found in close proximity.
This proximity is user-defined in the protocol and 
may involve metrics including \emph{RTT}s and network latencies.
By and large a clustering approach, \emph{mOverlay} seeks to 
recreate small-world-like properties by producing a 
two-level hierarchical structure:
at the top level, there are only connections among groups 
while at the bottom, only \emph{intra-group} connections occur among peers.

%%AD how do you identify the initial groups????
%%
%% VM REPHRASING IN ORDER TO ANSWER THE QUESTION ABOVE
Clearly, identifying groups and accurately finding the closest group 
to a peer is a fundamental concern in the creation of the overlay.
Nodes are grouped based on their distance to 
the groups already in the network, rendering
the latter be the \emph{dynamic landmarks} in the process. For a newcomming
peer $Q$ the \emph{grouping critirion} says that when the distance of $Q$ and
some group $A$’s neighbor groups is the same as the distance
between group $A$ and group $A$’s neighbor groups, then host $Q$
should belong to group $A$. During network initialization or when grouping
criterion is not met, new groups are created.
It is shown that in the proposed scheme, a new peer can 
reach its group by expending at most $O(logN)$ messages
within the network. 
Finally, \emph{mOverlay} maintains stability and constant 
overheads when a host either fails or departs the network;
this is achieved through periodic cache updates and group 
leader selections, should one either leaves or dies.
%
%\paragraph{Locating process} A new coming host, $Q$, first connects to a
%globally known host cache called the \emph{rendezvous point (RP)} in order to
%retrieve the starting point in the overlay, say $A$ in group $1$. Host $Q$
%then, measures its distance to host $A$. At the same time, the later, sends
%information about the neighbor groups of group $1$ back to host $Q$. This list
%is called \emph{candidate group list}, and the new coming host sequentially
%measures its distance to each of them in seek for the closest one. If the
%\emph{grouping criterion} is met, host $Q$ belongs to group $1$. If not, a boot
%host from the closest group is found and the algorithm is re-run until the
%criterion is met or after a predefined number of repetitions. In the later
%case, $Q$ creates a new group comprising itself only. The above protocol does
%not favor hot-spots as it spreads the probability of visiting a group across
%the whole overlay and limits the overhead in the level of $O \left ( log N
%\right )$.
%
%\paragraph{General overlay operations} A set of additional protocols, are also
% introduced, similar to those found in traditional unstructured networks, but
%modified focusing on scalability and robustness. For example a protocol for
%\emph{group formation} is introduced that exploits the inherent characteristic
%of proximity, in the overlay, in order to efficiently detect the neighboring
%groups of a newly formed group from the set of adjacent groups of its closest
%neighbor. Additionally, during \emph{group joining} the corresponding protocol
%denotes the exchange of important information for group maintenance. This can
%be further improved by \emph{information sharing} between nodes of the same
%group, functionality handled by a dedicated flood-like protocol\footnote{Since
%nodes that belong to the same group are physically close this can be achieved
%at a minimum price.}. Moreover, another set of distributed protocols handle the
%\emph{information update}. The information that needs update, in the proposed
%architecture, is
%\begin{inparaenum}[\itshape i\upshape)]
%  \item the host cache, when a new node joins, and
%  \item the neighbors of groups, when a close-by group is generated.
%\end{inparaenum}
%Finally, in case of \emph{host failure} or \emph{host departure} the system is
% able to maintain its stability since there are defined operations for
%periodical host cache update and group leader selection if one leaves or dies.
%
%%
In terms of the stated criteria, \emph{mOverlay} fares as follows:
\begin{center}
{\footnotesize
\begin{tabular}{ccc}
\emph{Efficiency} & \emph{Overhead} & \emph{Scalability} \\
\hline
% The technique is coarse grained thus doesn't achieve optimal results
% (especially in small networks)
medium &
% The algorithm is iterative through the available groups. At each group
% probing of a candidate list must be performed. This process is done at
% bootstrapping time so the overhead increases in high-churn systems
medium &
% The introduction of dynamic landmark servers renders this approach much more
% scalable than the traditional static landmarking techniques 
medium
\end{tabular}
}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Discussion on the Algorithms for Unstructured Architectures}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% TODO: HOW CAN UNSTRUCTURED SCHEMES BE REFINED
%
%For this reasons, efforts have been placed for optimizing the efficiency of
%decentralized unstructured peer-to-peer networks. Research mainly focuses on
%\begin{inparaenum}[\itshape i\upshape)]
%  \item reducing unnecessary, redundant communication traffic, and
%  \item exploiting physical locality to reduce communication response.
%\end{inparaenum}
%The goal can be achieved at, both, the application-level network as well as the
%underlying physical one. In the first case by refining the message relay
%techniques, while in the second one, by adaptively reconstructing the
%application network to map as well as possible to the the physical network.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

While surveying efforts to overcome the mismatch problem
in the area of unstructured \p\ systems,
we came to identify four key methodologies 
utilized by the discussed approaches; these methodologies are:
\begin{enumerate}[\itshape i\upshape)]
  \item topology adaptation
  \item forwarding optimization
  \item caching and replication, and
  \item landmarking
\end{enumerate}
%%VM Added the following to mention the hybrid/combo methodologies
An important aspect of many implementations, is that since the above
methodologies use heuristics to solve topology mismatch, an
intrinsically difficult problem, no single approach can offer a robust solution.
Thus, many of the algorithms we surveyed are actually combinations of multiple
such methodologies, in an attempt to refine the results of using just a single one.
For example, \emph{mOverlay} combines topology adaptation with landmark binning or \emph{Gia}
combines all three topology adaptation, forwarding optimization and caching
methodologies. Some times combination results in win/loose trade-offs. For
instance, the effectiveness of a caching/replication component can be undermined
by a continuously adapting overlay that removes important links between peers.
For this reason, the reader is advised to criticaly approach either the overall
algorithms or the separate methodologies when evaluating them for different
application domains.

Below, we discuss how the proposed protocols use elements of the four
methodologies and we offer a summary qualitative comparison for all surveyed
approaches applicable for \emph{unstructured} \p \emph{systems}.
%%VM I brought the following paragraph here from the end of this subsection.
Moreover, Table~\ref{unstructured:table} offers a summary overview for each effort,
showing which of the aforementioned methodologies it incorporates, along with its
highlights and a rough estimation of the positive and negative aspects of its
implementation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Topology Adaptation Methodology}

Protocols based on topology adaptation 
modify the topology of the \p\ network
using various techniques. The two most commonly used approaches to
topology adaptation are creating
\emph{spanning tree}s using connection graphs
and creating \emph{clusters} of physically close nodes.

\emph{Narada} and subsequent algorithms including 
\emph{AOTO, LTM, SBO}, try to solve the problem
by building a richer connected graph and forming 
minimum spanning trees over
this graph that can efficiently route messages among peers. The \emph{AOTO, LTM}
and \emph{SBO} try to
overcome this limitation with ingeneous schemes
like forming minimum spanning trees
for the $2$-hop away neighbors for each node, seperating participant nodes into
groups, sometimes with different responsiblities and tasks at hand (e.g.,
\emph{SBO}). The advantage of building minimum spanning trees is that
they maintain the connectivity on the network in
an efficient manner while still preserving the overall search scope.
However, their construction and the update costs,
especially in dynamic, high-churn environments,
causes large additional traffic overhead on the underlying
network~\cite{CRZ2000,CRSZ2001,CRSZ2002}.

The cluster-based approaches, on the other hand, 
link physically-close nodes to each other. 
\emph{T2MC}, for example, uses trace-route logs and 
\emph{DDNO} exploits domain names to cluster nodes in proximity at peer join.
Further enhancements may include dynamic local restructuring of the overlay
graph through neighbour exchange like in \emph{PROP} or cycle-cut like in
\emph{DCMP} to achieve continoous adaptation thoughout a peer's lifecycle.
Unfortunately, commonly used methods for proximity detection across Internet do
not always return
reliable results and therefore, mapping accuracy is not guaranteed. Specifically
for traceroute, its overhead is not negligible and routers or firewalls in a
network may have already been configured to disable traceroute response from
the start. The most problematic aspect of clustering, though, is
its nature per se. 
Limited connectivity among the various local domains can
significantly shrink the search scope, negatively affecting the query response
time that the \p\ user experiences. Among others, \emph{DDNO} tries to 
balance the efficiency of the clustering approach 
with enhanced node connectivity by forcing half of each node's connections to be
with other, randomly selected, nodes.

As a methodology, topology adaptation, ultimately aims to reduce the 
average path traversing cost from one node to another.
In doing so, topology adaptation re-arranges the
overlay network so that it becomes a better fit 
for the underlying \emph{IP} network.
% as Figure~\ref{figure:topology-adaptation} depicts.
Despite the fact that the above is a plausible proposition,
it is not always advantageous though. For example, a topology adaptive
algorithm can exchange a slow edge in the overlay with a faster one
thus reducing the average latency of the network communication.
The pitfall here is that this new virtual link
can traverse a fast \emph{AS}--to--\emph{AS} link meaning that even though
message round-trip-time is reduced, it has actually additional cost in terms of
inter-ISP communication accounting and management.

\begin{figure}[ht]
\centering
\subfigure[Inefficient overlay topology averaging $\simeq 16$ delay units.] {
  \includegraphics[scale=0.4]{img/pdf/topology-adaptation-before.pdf}
  \label{figure:topology-adaptation:before}
}\qquad\qquad
\subfigure[Efficient overlay topology after adaptation averaging $\simeq 11$ delay units.] {
  \includegraphics[scale=0.4]{img/pdf/topology-adaptation-after.pdf}
  \label{figure:topology-adaptation:after}
}
\caption{A simplified example on how overlay topology adaptation may improve matters.}
\label{figure:topology-adaptation}
\end{figure}
%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Forwarding Optimization Methodology}
Approaches based on forwarding-optimization 
propose intelligent forwarding link selection for a message's next
hop across a routing path. 
The selection criteria vary depending on the
algorithm, but they mainly use one or more statistical heuristics. 
These can range from simple connection speed, to exploiting specific peer
attributes such as high processing capacity e.t.c. An example is \emph{Gia} that
exploits the so called heterogeneity of peers as well as employs a token-based
flow control mechanism to guide the messages towards peers that are more likelly
to answer
a query. More sophisticated alternatives also exist,
taking into account application level requirements or exploiting machine
learning techniques to adjust to overlay network routing, like the \emph{APS}
algorithm.

Figure~\ref{figure:forwarding-optimisation} shows a simple example
of how forwarding optimization may work.
%%
\begin{figure}[ht]
\centering
\subfigure[Typical blind flooding.] {
\includegraphics[scale=0.20]{img/pdf/forwarding-optimization-before.pdf}
  \label{figure:forwarding-optimisation:before}
}\qquad\qquad
\subfigure[A node can decide where to forward the messages.] {
  \includegraphics[scale=0.20]{img/pdf/forwarding-optimization-after.pdf}
  \label{figure:forwarding-optimisation:after}
}
\caption{Forwarding optimization in constraining message flooding.}
\label{figure:forwarding-optimisation}
\end{figure}
%%
Fig.~\ref{figure:forwarding-optimisation:before} 
shows a protocol that simply floods the entire network 
in search of object found in the nodes colored in black.
Alternatively, a node can decide to forward its
messages not to every output link but to a specific 
or subset of its outgoing links.
In Fig.~\ref{figure:forwarding-optimisation:after}, 
the node in the middle, does not flood its neighbors as instead 
in only picks one of them.
The dashed line on the right, shows that, 
for this routing process, the protocol has
rendered two potential forwarding paths as inefficient (e.g., the target nodes
show overloading signs). 
On one hand, forward
optimisation approaches have 
the advantage of enhancing the
search responsiveness and reducing the aggregate resource 
usage of the physical network. On the other, 
they suffer from drastic reduction of the search
scope (in Fig.~\ref{figure:forwarding-optimisation:after} the object on
the far right is not reached) thus limiting the scalability of the whole
network. 
Moreover, they adress the problem of the mismatch in a limited manner
since they do not provide any guarantees 
that overlay and underlying topologies are
aligned with each other let alone quantify the mismatch 
and try to alleviate.
Forwarding based optimisations are commonly applied in
conjunction with other methodologies to improve 
the quality of the \p\ systems.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Caching and Replication Methodology}

Caching is widely used to exploit locality and minimize redundant
transfer of data. Caching has with much success been successfully 
adopted by web and file server application environments. 
Since peers in a \p\ system also operate as servers,
it is intuitively expected that \p\ file sharing systems can also benefit from
caching in improving performance and reducing overall resource usage. 
However, the design of caches in this context 
is non-trivial compared to the web-based caching. 
Due to the fact nodes play the double role of server and client,
two important issues have to be considered at design time. 
First, the lifetime of a query is short, as the nodes join 
and leave frequently. Second, the result
of a single query string is not always the same, as this depends on the
source of the query, the \emph{TTL} value set for the messages, 
the current interconnection of peers and the 
high volatility of the environment. 
Thus, to develop a successful caching system for a \p\ architecture, these
parameters also have to be carefully considered. 
\p\ caching/replication can be applied
at two different levels, namely caching indices or pointers to data 
(Fig.~\ref{figure:replication:index}) or caching the data itself 
(Fig.~\ref{figure:replication:data}). 
%%%
\begin{figure}[ht]
\centering
\subfigure[Indexing can reduce the cost of the last hop.] {
\includegraphics[scale=0.3]{img/pdf/replication-index.pdf}
  \label{figure:replication:index}
}\qquad\qquad
\subfigure[Data replication along the path of a successful query.] {
  \includegraphics[scale=0.3]{img/pdf/replication-data.pdf}
  \label{figure:replication:data}
}
\caption{Index and data replication strategies.}
\label{figure:replication}
\end{figure}
%%
Successful implementations have
already been developed in some commercial \p\ systems, like 
\emph{KaZaA} or less well known like \emph{Gia} and \emph{BNS} as we saw during
the survey.
%%%
Even though the state of the art in \p\ protocols using caching methods
helps reduce the burden of network resources, 
their contribution in addressing the actual mismatch between the overlay and
and the underlying networks remains limited.

% TODO SOME DISCUSSION
%The caching policy varies depending on the way protocol handles the
%index and the
%content. Centralized P2P systems
%use central index servers, while local caching systems, such as KazaA, use
%super peers
%to cache indices in a distributed way. Content caching is also possible in P2P
%systems, where nodes cache the forwarded content for further retrievals.
%Although caching has the above mentioned advantages,  duplication
%of messages still exist, which limits the scalability of these approaches.
%Therefore, cache based approaches are analyzed in the following categories:
%  \begin{itemize}
%    \item \emph{data index caching},
%    \item \emph{content index caching},
%    \item \emph{centralized}, and
%    \item \emph{local}.
%  \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Landmarking}\label{sec:landmark}

In landmark-based algorithms, nodes use network delay (e.g., \emph{RTT}) as a
distance measurement method to position themselves with respect to ``a priori''
known servers on the Internet, like \emph{Ono} which uses the CDN-infrastructure
for this purpose.
These landmark servers are used
by nodes to estimate their positions based on the intuitive assumption that
nodes
with similar distances to a set of landmarks, are physically close to each
other, as well, over the network. 
In Figure~\ref{figure:landmarking} the newly
arriving peer, measures its distance to an array of landmark point denoted as
$L_n$ and and makes a sorted list of the peers, say in increasing order. Then in
order to choose the already participating peers with which to connect to,
compares its list to the list of the potential neighbor. Peers with similar
measured distances to the these landmark points are likely to be close to
each other as well.
%%
\begin{figure}[ht]
\centering
  \includegraphics[scale=0.4]{img/pdf/landmarking.pdf}
\caption{Landmark binning during node bootstrap.}
\label{figure:landmarking}
\end{figure}

Landmark based protocols have four important drawbacks: First, the network
delay is not a reliable distance estimation method. For example, based on the
load on the network, the delay to certain nodes or networks can change from time
to time, which will eventually affect the distance measurements and wrong
measurements will lead to wrong estimated positions for the nodes, or incorrect
and non optimal clusterings of the nodes. Second, relying on predefined nodes
make the whole paradigm not fully distributed and the landmark system prone to
become a single point of failure. Third, using
landmark servers requires costly installation and maintenance of landmark
infrastructure across the whole Internet and for all the different autonomous
system domains. 
As popular \p\ file sharing applications usually have millions
of peers connected at any time, the network costs
of maintaining these landmark servers will likely be quite high. 
A possible solution to
the scalability problem of the static landmark servers is to use ordinary nodes
as dynamic landmarks, like in \emph{mOverlay} once they estimate their own positions. Even though this
approach scales much better than static landmark servers, the measurement
accuracy problem affects the overall performance of the system. Moreover,it can
be characterized as a rather coarse-grained approximation, therefore not
particularly well suited for detecting the correct positions of nodes within
close distance to each other.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{unstructured-table}

\input{unstructured-plot}
